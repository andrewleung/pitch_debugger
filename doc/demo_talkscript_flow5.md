## **Flow 5 Demo Talkscript (≈2–3 minutes) — “Underwritable Gates” (rubrics as go/no-go checkpoints)**

**0\) Setup (before first click)**

“Flow 5 is the core idea: we don’t treat diligence as a vibe check. We treat it as gates.  
Each gate is a rubric-based checkpoint that says ‘go / no-go’ and—if it’s no-go—exactly what work is required to get back to ‘forwardable’.”

**(Open DevTools → Console)**

“I’ll keep the console open so you can see the gate outputs and reasons.”

---

### **1\) Show the failure mode: thin inputs → FAIL gates**

**Click: *Make it thin (fail gates)***

“This is what most teams start with—generic problem, generic ICP, no evidence linkage, no IP delta, no disclosure control.”

**Click: *Run All Gates***

“Now we run the gates. Watch what happens: it doesn’t just say ‘this is bad.’  
It fails specific gates with specific reasons.”

Point at the gates panel:

“Gate 1 checks problem clarity: do we have a real buyer and a specific pain?  
Gate 2 checks evidence coverage: do our claims link to receipts?  
Gate 3 checks IP delta: do we know the adjacency and the novelty delta, and do we have an action plan?  
Gate 4 checks safe disclosure: can we share without leaking the secret sauce?  
And Gate 5 is forwardability: overall go/no-go.”

---

### **2\) Show the key behavior: FAIL produces tasks (not shame)**

Point at Task Board:

“Here’s the important part: every failing gate produces remediation tasks—what we call the evidence plan.  
This is the Workflow OS behavior: convert rubric failure into concrete work.”

Optional one-liner:

“So the system doesn’t just grade you—it tells you what to do next.”

---

### **3\) Close blockers fast: Autofix \= doing the work \+ generating receipts**

**Click: *Autofix* (1st time)**

“Autofix simulates completing a couple tasks—preferably blockers.  
When tasks complete, the system generates evidence objects—structured receipts.”

Point at Evidence Vault:

“Notice evidence is JSON. That’s intentional: it’s compilable and auditable.”

---

### **4\) Re-run gates: improvements are visible and measurable**

**Click: *Run All Gates***

“Now we re-run the gates. You’ll see fewer FAILs and a higher score.  
The key is: we’re not guessing what improved; the rubric makes it measurable.”

Call out a specific gate that flips or improves:

“Evidence coverage improves because we added an evidence map.  
Disclosure improves because we created a safe publish stub.  
IP delta improves once we record an action plan.”

---

### **5\) Push toward PASS: clear multi-gate issues with one or two high-leverage tasks**

**Click: *Autofix* (2nd time)**

“We do another pass. In real life, this is your team doing the work—interviews, receipts, IP analysis, redaction rules.”

**Click: *Run All Gates***

“Now we’re approaching overall PASS.  
When the gates pass, that’s the moment the artifact becomes safe to forward internally.”

---

### **6\) Compile only when it’s underwritable**

**Click: *Compile / Recompile***

“Now Pitch Debugger compiles the pack.  
The compiled output includes a gate summary, evidence index, and task status—so the receiver can see what’s solid and what’s still open.”

Point at Forwardable status:

“This is the main promise: the artifact stays *underwritable*.  
It’s forwardable not because it’s polished—but because it’s gated and evidenced.”

---

## **Close (what Flow 5 proves)**

“Flow 5 proves rubrics can be operational.  
Underwriting becomes a loop: run gates → generate tasks → produce receipts → re-run gates → compile.  
That’s how you keep a Decision Pack forwardable as diligence deepens—without relying on heroics.”

### **Optional 15-second add-on (if asked “who is this for?”)**

“For founders, it tells you exactly what to do next.  
For investors, it gives you a forwardable artifact with explicit confidence.  
For counsel, it structures claim hooks and disclosure boundaries.”

If you want, paste the exact gate names you want (e.g., “Market Truth Gate”, “Moat Gate”, “Risk Bound Gate”), and I’ll rewrite this script to match your preferred nomenclature.

